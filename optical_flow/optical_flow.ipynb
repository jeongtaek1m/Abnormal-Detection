{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2867,
     "status": "ok",
     "timestamp": 1701097026277,
     "user": {
      "displayName": "­문희준 | 인공지능학과 | 한양대(서울)",
      "userId": "12627775913057364184"
     },
     "user_tz": -540
    },
    "id": "yAKXA7Z7Gwz0",
    "outputId": "612196d8-1366-4650-c628-3ad957a2bf19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# # connect google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IAMDrBMnClu"
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lrjtVs-oGODv"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHVW6Ht3nE_L"
   },
   "source": [
    "# Part1: goodFeaturesToTrack\n",
    "- Fill the missing part (denoted as ```fill here```) of the code\n",
    "- We provide procedure comments for complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "AEPUBxp_GPpl"
   },
   "outputs": [],
   "source": [
    "def goodFeaturesToTrack(image, maxCorners=100, qualityLevel=0.03, blocksize=7):\n",
    "\n",
    "    # Image bluring wih averaging filter\n",
    "    # Only cv2.filter2D is allowed for convolution operation!\n",
    "    average_filter = np.ones((blocksize, blocksize), np.float32)/(blocksize*blocksize)\n",
    "    # gaussian_filter = np.array([[1/16, 2/16, 1/16], [2/16, 4/16, 2/16], [1/16, 2/16, 1/16]])\n",
    "    image = cv2.filter2D(image, -1, average_filter) / 255.0\n",
    "\n",
    "    # Compute gradients\n",
    "    Ix = cv2.filter2D(image, -1, np.array([[-1/2, 0, 1/2]]))\n",
    "    Iy = cv2.filter2D(image, -1, np.array([[-1/2], [0], [1/2]]))\n",
    "\n",
    "    # Compute products of gradients at each pixel\n",
    "    Ixx = Ix * Ix\n",
    "    Iyy = Iy * Iy\n",
    "    Ixy = Ix * Iy\n",
    "\n",
    "    # Compute the sums of products of gradients in local windows\n",
    "    Sxx = cv2.filter2D(Ixx, -1, np.ones((3, 3)))[1:-1, 1:-1]\n",
    "    Syy = cv2.filter2D(Iyy, -1, np.ones((3, 3)))[1:-1, 1:-1]\n",
    "    Sxy = cv2.filter2D(Ixy, -1, np.ones((3, 3)))[1:-1, 1:-1]\n",
    "\n",
    "    # Compute the determinant and trace of the matrix M for each pixel\n",
    "    detM = Sxx * Syy - Sxy**2\n",
    "    traceM = Sxx + Syy\n",
    "\n",
    "    # Compute the Harris response with detM and traceM\n",
    "    harris_response = detM - qualityLevel * (traceM**2)\n",
    "\n",
    "    # Threshold the Harris response to find candidate corners\n",
    "    corners = np.argwhere(harris_response >= 0.1 * np.max(harris_response))\n",
    "\n",
    "    # Sort the corners by Harris response in descending order\n",
    "    sorted_corners = corners[np.argsort(harris_response[corners[:, 0], corners[:, 1]])[::-1]]\n",
    "\n",
    "    # Keep the top 'maxCorners' corners\n",
    "    selected_corners = sorted_corners[:maxCorners]\n",
    "\n",
    "    final_corners = np.array(selected_corners) + 1\n",
    "    final_corners = final_corners.reshape(-1, 1, 2)\n",
    "\n",
    "    return final_corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gcb42xzntML"
   },
   "source": [
    "# Part2: Optical flow with Lukas-Kanade\n",
    "- Fill the missing part (denoted as ```fill here```) of the code\n",
    "- We provide procedure comments for complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "lv7zvb_nG8ql"
   },
   "outputs": [],
   "source": [
    "\n",
    "def optical_flow(old_frame, new_frame, window_size, min_quality):\n",
    "\n",
    "    feature_list = goodFeaturesToTrack(old_frame, max_corners, min_quality, blocksize)\n",
    "\n",
    "    w = int(window_size/2)\n",
    "\n",
    "    # Normalize\n",
    "    old_frame = old_frame / 255\n",
    "    new_frame = new_frame / 255\n",
    "\n",
    "    # Convolve to get gradients w.r.to X, Y and T dimensions\n",
    "    kernel_x = np.array([[-1/2, 0, 1/2]])\n",
    "    kernel_y = np.array([[-1/2], [0], [1/2]])\n",
    "    kernel_t = np.array([[1]])\n",
    "\n",
    "    # cv2.filter2D is allowed for convolution!\n",
    "    fx =  cv2.filter2D(old_frame, -1, kernel_x)\n",
    "    fy =  cv2.filter2D(old_frame, -1, kernel_y)\n",
    "    ft =  cv2.filter2D(new_frame - old_frame, -1, kernel_t)\n",
    "\n",
    "    u = np.zeros(old_frame.shape)\n",
    "    v = np.zeros(old_frame.shape)\n",
    "\n",
    "    for feature in feature_list:  # for every corner\n",
    "        i, j = feature.ravel()  # get cordinates of the corners (i,j).\n",
    "        i, j = int(i), int(j)  # i,j are floats initially so convert to integer type\n",
    "\n",
    "        I_x = fx[i-w:i+w+1, j-w:j+w+1].ravel()\n",
    "        I_y = fy[i-w:i+w+1, j-w:j+w+1].ravel()\n",
    "        I_t = ft[i-w:i+w+1, j-w:j+w+1].ravel()\n",
    "\n",
    "        b = np.reshape(I_t, (I_t.shape[0], 1))      # b : (225, 1)  225가 아닌 195 or 210 인 경우도 존재\n",
    "        A = np.vstack((I_x, I_y)).T                 # A : (225, 2)  225가 아닌 195 or 210 인 경우도 존재\n",
    "\n",
    "        weight_size = A.shape[0]\n",
    "        weight_vec = np.identity(weight_size) / 2\n",
    "        if weight_size // 2:\n",
    "            # weight_vec[int(weight_size/2)-int(weight_size/4):int(weight_size/2)-int(weight_size/4)+1,\n",
    "            #            int(weight_size/2)-int(weight_size/4):int(weight_size/2)-int(weight_size/4)+1] = 0.5\n",
    "            weight_vec[int(weight_size/2),int(weight_size/2)] = 1.0\n",
    "        else:\n",
    "            # weight_vec[int(weight_size/2)-int(weight_size/4):int(weight_size/2)-int(weight_size/4)+1,\n",
    "            #            int(weight_size/2)-int(weight_size/4):int(weight_size/2)-int(weight_size/4)+1] = 0.5\n",
    "            weight_vec[int(weight_size/2)-1:int(weight_size/2)+1,int(weight_size/2)-1:int(weight_size/2)+1] = 1.0\n",
    "        Weight = weight_vec   # Weight : (A.shape[0], A.shape[0])\n",
    "\n",
    "        # U = (np.linalg.pinv(A.T @ A)) @ (A.T @ b)  # Solving for (u,v) i.e., U\n",
    "        U = (np.linalg.pinv(A.T @ Weight @ A)) @ (A.T @ Weight @ b)\n",
    "\n",
    "        u[i, j] = U[0][0]\n",
    "        v[i, j] = U[1][0]\n",
    "\n",
    "    return (u, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4N4xHKEHAjA"
   },
   "source": [
    "# Main function\n",
    "- If part1 and part2 were filled properly, the 'output.avi' will be generated!\n",
    "- For google colab, as cv2.imshow() is not provided, so please use cv2_imshow (google.colab.patches) instead  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "APQHNcblG_Jp",
    "outputId": "1191d4ce-4a66-46ac-d50b-d2a54b97a83e"
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('/content/drive/MyDrive/CV_project/optical_flow/slow.mp4')\n",
    "cap = cv2.VideoCapture('C:/Users/jeong/Desktop/3_2학기/Computer_vision/CV_project/optical_flow/slow.mp4')\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "\n",
    "# Width and height of the file to save\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "# 'output.mp4' will be generated!\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('output.mp4',  fourcc, 30.0, (int(width), int(height)))\n",
    "\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Shi Tomasi parameter\n",
    "max_corners = 100\n",
    "min_quality = 0.05      # initial : 0.03\n",
    "blocksize = 7\n",
    "p0 = goodFeaturesToTrack(old_frame, max_corners, min_quality, blocksize)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret, current_frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # calculate optical flow\n",
    "    U, V = optical_flow(old_gray, frame_gray, 15, min_quality)\n",
    "\n",
    "    for i in range(current_frame.shape[0]):\n",
    "        for j in range(current_frame.shape[1]):\n",
    "            u, v = U[i][j], V[i][j]\n",
    "            if u and v:\n",
    "                mask = cv2.line(mask, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), 2)\n",
    "                frame = cv2.arrowedLine(current_frame, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), thickness=2)\n",
    "                current_frame = cv2.add(current_frame, mask)\n",
    "\n",
    "    # Display the frame with optical flow vectors\n",
    "    cv2.imshow(\"frame\", current_frame)\n",
    "    # cv2.imshow(\"gray\", frame_gray)\n",
    "    out.write(current_frame)\n",
    "    # Break the loop if 'Esc' key is pressed\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "    # Set the current frame as the previous frame for the next iteration\n",
    "    old_gray = frame_gray\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Close the plot window when done\n",
    "plt.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
